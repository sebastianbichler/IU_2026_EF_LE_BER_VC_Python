# Konzept â€“ FoxExpress ğŸššğŸ’¨

## Leitfrage â“

**â€Leistungsanalyse von JIT-Kompilierungsstrategien in dynamischen Sprachen:  
Ein Vergleich zwischen methodenbasierter (Numba) und tracingbasierter (PyPy) JIT-Kompilierung bei algorithmisch geprÃ¤gten Workloads.â€œ**

---

## ErlÃ¤uterung & Problemstellung ğŸ“Œ

Ziel des Projekts **â€FoxExpressâ€œ** ist die Entwicklung einer vereinfachten Logistik-Software, mit der Lieferungen verwaltet und kÃ¼rzeste Lieferwege berechnet werden kÃ¶nnen. 

Auf dieser Grundlage wird die Laufzeit identischer Routing-Algorithmen (Dijkstra-Algorithmus) unter verschiedenen Python-AusfÃ¼hrungsumgebungen systematisch verglichen:

- **CPython** (Referenz-Interpreter)
- **PyPy** (Tracing-basierte JIT-Kompilierung)
- **Numba** (Methodenbasierte JIT-Kompilierung)

### Wissenschaftlicher Hintergrund

Dynamisch typisierte und interpretierte Sprachen wie CPython bieten eine hohe EntwicklerproduktivitÃ¤t, weisen jedoch bei rechenintensiven algorithmischen Workloads messbare Performance-Nachteile auf. In der Literatur werden insbesondere wiederholte Boxing- und Unboxing-Operationen sowie dynamische FunktionsauflÃ¶sung (Late Binding) als relevante Quellen interpretativen Overheads beschrieben (Barany, 2014; Tuominen, 2025).

DarÃ¼ber hinaus fÃ¼hren mehrstufige Indirektionen beim Zugriff auf Python-Objekte zu zusÃ¤tzlichem Laufzeitaufwand, insbesondere bei schleifenbasierten numerischen Operationen (Lam, Pitrou, & Seibert, 2015). Diese Eigenschaften sind insbesondere bei graphbasierten Algorithmen wie Dijkstra relevant, da sie stark iterativ geprÃ¤gt sind.

Zur Reduktion dieses Overheads kommen Just-in-Time-Kompilierungsstrategien (JIT) zum Einsatz. JIT-Kompilierung bezeichnet die Ãœbersetzung von Code zur Laufzeit in maschinennahen Code, wodurch interpretative Zwischenschritte reduziert werden kÃ¶nnen (Genchev et al., 2025).

In diesem Projekt werden zwei unterschiedliche JIT-AnsÃ¤tze untersucht:

- **Tracing-basierte JIT-Kompilierung (PyPy):**  
  HÃ¤ufig ausgefÃ¼hrte Codepfade (â€Hot Pathsâ€œ) werden wÃ¤hrend der Laufzeit identifiziert und optimiert.

- **Methodenbasierte JIT-Kompilierung (Numba):**  
  Einzelne annotierte Funktionen werden mittels LLVM in optimierten Maschinencode Ã¼bersetzt (Lam et al., 2015).

Ziel ist es, die Effizienz dieser beiden Strategien im Kontext algorithmischer Workloads systematisch zu vergleichen.

---

## Systemaufbau ğŸ§©

Konzeptionell besteht **â€FoxExpressâ€œ** aus:

- einem Modul zur Lieferverwaltung  
- einem Routing-Modul zur Berechnung kÃ¼rzester Wege mittels **Dijkstra-Algorithmus**  
- einer grafischen BenutzeroberflÃ¤che (realisiert mit **Streamlit**)  

### Architektonische Entscheidung

Das System folgt einem modularen Design, in dem rechenintensive Routing-Operationen strikt von der BenutzeroberflÃ¤che getrennt sind. Ziel dieser Trennung ist es, algorithmische Berechnungen isoliert auszufÃ¼hren und deren Laufzeitverhalten unabhÃ¤ngig von GUI-Interaktionen zu messen.

FÃ¼r den Vergleich mit PyPy wird ein separater Interpreterprozess Ã¼ber die Standardbibliothek `subprocess` gestartet. Dadurch wird sichergestellt, dass jede AusfÃ¼hrungsumgebung unter klar getrennten und kontrollierten Laufzeitbedingungen evaluiert wird. Diese Trennung dient der methodischen Konsistenz und Vergleichbarkeit der Messergebnisse.

---

## Methodik â±ï¸

Die Evaluation erfolgt in Form eines experimentellen Leistungsvergleichs identischer algorithmischer Workloads.

### Benchmark-Design

- Identische Eingabedaten fÃ¼r alle AusfÃ¼hrungsumgebungen
- Wiederholte DurchfÃ¼hrung der Berechnungen
- Messung der reinen AusfÃ¼hrungszeit
- Vergleich aggregierter Laufzeitwerte

Zur Sicherstellung reproduzierbarer Ergebnisse werden alle Tests unter identischen Hardware- und Softwarebedingungen durchgefÃ¼hrt.

Die Ergebnisse werden statistisch ausgewertet und in der grafischen OberflÃ¤che vergleichend dargestellt.

---

## Technologien & Entscheidungen ğŸ› ï¸

Zur Umsetzung der Anforderungen wurden folgende technische Entscheidungen getroffen:

### NumPy

NumPy dient als primÃ¤re Datenstruktur fÃ¼r die interne ReprÃ¤sentation des Graphen.

**BegrÃ¼ndung:**  
Numba fokussiert sich auf ein Python-Subset, das stark auf `ndarray`-Strukturen und numerischen Skalaren basiert (Lam et al., 2015). Durch die homogene Speicherstruktur von NumPy-Arrays kann Numba direkten Zugriff auf Datenpuffer ermÃ¶glichen und Indirektionskosten reduzieren. Standard-Python-Listen bieten diese Eigenschaften nicht.

---

### Numba (JIT)

Numba wird zur methodenbasierten Beschleunigung des Routing-Algorithmus eingesetzt.

**BegrÃ¼ndung:**  
Numba analysiert CPython-Bytecode, fÃ¼hrt Typinferenz durch und generiert daraus LLVM Intermediate Representation (LLVM IR), die anschlieÃŸend in Maschinencode Ã¼bersetzt wird (Lam et al., 2015). Im sogenannten â€nopython modeâ€œ erfolgt die AusfÃ¼hrung ohne RÃ¼ckgriff auf die Python C-API, wodurch interpretativer Overhead reduziert werden kann.

---

### PyPy

PyPy wird als tracingbasierter JIT-Interpreter verwendet.

**BegrÃ¼ndung:**  
Tracing-basierte JIT-Systeme identifizieren zur Laufzeit hÃ¤ufig ausgefÃ¼hrte Codepfade und optimieren diese dynamisch. Dieser Ansatz unterscheidet sich grundlegend von der funktionsbasierten Kompilierung durch Numba und erlaubt einen konzeptionell unterschiedlichen Optimierungsansatz.

---

### Subprocess (Standardbibliothek)

Der Vergleich mit PyPy erfolgt durch den Start eines separaten Interpreterprozesses.

**BegrÃ¼ndung:**  
Die Prozessisolierung stellt sicher, dass jede Laufzeitumgebung unabhÃ¤ngig initialisiert wird. Dadurch wird eine konsistente Vergleichsbasis geschaffen und unbeabsichtigte Interferenzen zwischen den Laufzeitumgebungen vermieden.

---

### NetworkX

NetworkX wird zur logischen Modellierung und Generierung der Graphen verwendet.

**BegrÃ¼ndung:**  
Die Bibliothek ermÃ¶glicht eine strukturierte Erstellung komplexer Testnetzwerke, bevor diese fÃ¼r die eigentliche Berechnung in eine Numba-kompatible Datenstruktur Ã¼berfÃ¼hrt werden.

---

### Matplotlib / Streamlit Native Charts

Zur Visualisierung der Benchmark-Ergebnisse werden integrierte Diagrammwerkzeuge verwendet.

**BegrÃ¼ndung:**  
Die gewÃ¤hlten Werkzeuge ermÃ¶glichen eine hinreichend prÃ¤zise Darstellung der Messergebnisse bei gleichzeitig reduzierter technischer KomplexitÃ¤t.

---

## Literaturverzeichnis

Barany, G. (2014). *Analysis of performance overhead in CPython interpreter*.  

Genchev, E., Rangelov, D., Waanders, K., & Waanders, S. (2025). Utilizing JIT Python runtime and parameter optimization for CPU-based Gaussian Splatting thumbnailer. *Array, 28*, 100611.  

Lam, S. K., Pitrou, A., & Seibert, S. (2015). Numba: A LLVM-based Python JIT compiler. In *Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC* (pp. 1â€“6). ACM.  

Tuominen, J. (2025). *JIT Compiling CPython with Numba & JAX* (Bachelorâ€™s Thesis). Tampere University.
